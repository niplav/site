Unfortunately, I don't know of a good write-up of the argument for why BCIs wouldn't be *that* useful for AI alignment (maybe I should go and try to write it out – so many things to write). Superintelligence ch. 2 by Bostrom explains why it seems unlikely that we will create superintelligence by BCIs, but doesn't explain why, even if they existed, they would be unhelpful for alignment.

Arguments against why BCIs might be use/helpful:

* There doesn't seem to be a clear notion of what it would mean for humans to merge with AI systems/no clear way of stating how having
  * Humans [likely don't have fully specified coherent utility functions](https://nivlab.princeton.edu/publications/case-against-economic-values-brain), and there also doesn't seem to be an area in the brain that is the *value module* so that we could plug it into the AI system as a utility function
  * Human augmentation with AI systems of [infrahuman capability](https://arbital.com/p/relative_ability/) might work, but might carry the risk of causing amounts of value drift large enough to count as human values being lost
  * Human augmentation with [superhuman (or even par-human)](https://arbital.com/p/relative_ability/) AI systems seems pretty bad: if the AI system is unaligned to begin with, it probably doesn't help you if it has *direct access to your brain and therefore your nervous system*
  * Using humans in AI systems as [approvers/disapprovers](https://www.lesswrong.com/posts/7Hr8t6xwuuxBTqADK/approval-directed-agents-1) works just as fine with screens & keyboards
* To re-emphasise: It seems really really bad to have an unaligned AI system plugged into your brain, or to provide attack vectors for possible unaligned future AI systems

Arguments for why BCIs might be useful:

* Humans would become effectively a bit more intelligent (though I'd guess that functional intelligence would be <2x what we have now)
* Reaction times compared to AI systems would be sped up (maybe by around 10x – BCIs seem faster than typing on a keyboard, but not *that* much, since we're limited by processing speed (brain at 200 Hz, CPUs at 2000000000 Hz, and GPUs/TPUs with similar orders of magnitude), not reaction speed)
* BCIs might help with human imitation/[WBEs](https://www.fhi.ox.ac.uk/brain-emulation-roadmap-report.pdf): the more information you have about the human brain, the easier it is to imitate/emulate it.
* BCIs and human augmentation might lessen the pressure to create AGI due to high economic benefits, especially if coupled with [KANSI](https://arbital.com/p/KANSI/) infrahuman systems

My intuition is that the pro-usefulness arguments are fairly weak (if more numerous than the anti arguments), and that there is no really clear case *for* BCIs in alignment, especially if you expect AI growth to speed up (at least, I haven't run across it, if someone knows one, I'd be interested in reading it). They mostly rely on a vague notion of humans and AI systems merging, but under closer inspection, so far they don't really seem to respond to the classical AI risk arguments/scenarios.

My tentative belief is that direct alignment work is probably more useful.
