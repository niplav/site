[home](./index.html)
---------------------

*author: niplav, created: 2022-07-28, modified: 2022-07-28, language: english, status: notes, importance: 5, confidence: unlikely*

> __A note on the effective altruism community pointing out a tension
between truth-seeking and effecitveness present in the community.__

Effective Altruism is a Pareto Frontier of Truth and Power
===========================================================

In order to be effective in the world one needs to coordinate
(exchange evidence, enact plans in groups, find shared descriptions
of the world) and interact with hostile entities (people who lie,
people who want to steal your resources, subsystems of otherwise
aligned people who want to do those things, engage in public
relations or zero-sum conflict). Solving those often requires trading
off truth for "power" on the margin, e.g. by nudging members to
"just accept" conclusions for action believed to be a basis for
effective action (since making elaborate arguments common knowledge [is
costly](https://www.lesswrong.com/posts/9QxnfMYccz9QRgZ5z) and agreement
converges slowly on evidence-sharing<!--TODO: link Aaronson post on
Complexity of Disagreement-->), by [misrepresenting beliefs to other
actors](https://www.lesswrong.com/s/uLEjM2ij5y3CXXW6c/p/fhJkQo34cYw6KqpH3)
to make them more favorable towards effective
altruism, or by choosing easy-communicable [Schelling
categories](https://www.lesswrong.com/s/yiFxBWDXnLpbWGTkK/p/edEXi4SpkXfvaX42j)
that minmax utility to the lowest-bounded agents.

On the one side of the Pareto frontier one would have an even more
akrasia-plagued version of the rationality community with excellent
epistemics but which would be universally hated, on the other hand one
would have the attendants of [this party]()<!--TODO: link Aella post-->.

Members of effective altruism seem not explicitely aware of this tradeoff
(maybe for power-related reasons?) or at least don't talk about it,
even though it appears to be relevant.
